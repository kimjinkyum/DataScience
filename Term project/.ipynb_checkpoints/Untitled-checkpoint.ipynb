{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import math,os,re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "#read orinial data\n",
    "data=pd.read_csv(\"../data/data.csv\",encoding = \"ISO-8859-1\")\n",
    "\n",
    "column=original.columns[:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " #preprocessing city by calling cityPreprocess function.\n",
    "data=cityPreprocess(data) \n",
    "\n",
    "    #preprocessing host_id, id by calling idPreprocess function.\n",
    "data=idPreprocess(data)\n",
    "\n",
    "    #preprocessing data drop null value in property_type, room_type, bed_type by calling dropna\n",
    "data=dropna(data,\"property_type\")\n",
    "data=dropna(data,\"room_type\")\n",
    "data=dropna(data,\"bed_type\")\n",
    "data=data.dropna(subset=[\"bathrooms\",\"bedrooms\",\"beds\",\"accommodates\"])\n",
    "\n",
    "    #preprocessing zipcode, latitude, longitude by calling zipcodePreprocess, locationPreprocess\n",
    "    #, zipcodeLocationPreprocess, fillLocation\n",
    "data=zipcodePreprocess(data)\n",
    "data=locationPreprocess(data)\n",
    "data=zipcodeLocationPreprocess(data)\n",
    "fillLocation(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-533f649e7bf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#preprocessing bathroom,beds by calling roomPreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbathroom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mroomPreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#preprocessing property type,room type,bed type by calling oneHotPreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# onehot_property/roomtype/bedtype_label: sequence of property/room/bed type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f1f7b46112c9>\u001b[0m in \u001b[0;36mroomPreprocess\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropDigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;31m# convert wrong value(float) by calling covertFloat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f1f7b46112c9>\u001b[0m in \u001b[0;36mdropna\u001b[1;34m(origin, feacture)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeacture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m#drop null value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"all\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeacture\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m     \u001b[1;31m#reassign index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jinkyum\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   4857\u001b[0m                 \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4858\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4859\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4860\u001b[0m                 \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: [0]"
     ]
    }
   ],
   "source": [
    "#preprocessing bathroom,beds by calling roomPreprocess\n",
    "bathroom, beds= roomPreprocess(data)\n",
    "\n",
    "#preprocessing property type,room type,bed type by calling oneHotPreprocessing\n",
    "# onehot_property/roomtype/bedtype_label: sequence of property/room/bed type\n",
    "# onehot_propertyroomtype/bedtype: result of oridinal encoder\n",
    "onehot_property_label, onehot_property=OneHotPreprocessing(data,\"property_type\")\n",
    "onehot_roomtype_label,onehot_roomtype=OneHotPreprocessing(data,\"room_type\")\n",
    "onehot_bedtype_label,onehot_bedtype=OneHotPreprocessing(data,\"bed_type\")\n",
    "\n",
    "#preprocessing minimum nights and maximum nights by calling minimumNightPreprocess\n",
    "minimumNightNewFeature = minimumNightPreprocess(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store preprocessed data\n",
    "global preprocessed_data\n",
    "\n",
    "\n",
    " #copy data to preprocessed_data\n",
    "preprocessed_data=data.iloc[:,:]\n",
    "\n",
    "    #change result to preprocessed\n",
    "preprocessed_data[\"property_type\"]=onehot_property\n",
    "preprocessed_data[\"room_type\"]=onehot_roomtype\n",
    "preprocessed_data[\"bed_type\"]=onehot_bedtype\n",
    "preprocessed_data[\"beds\"]=beds\n",
    "preprocessed_data[\"bathrooms\"]=bathroom\n",
    "\n",
    "\n",
    "\n",
    "colCat=preprocessed_data['amenities'].as_matrix().reshape(-1)\n",
    "colCat=str(colCat).split(',')\n",
    "trimming(colCat)#특수기호 제거\n",
    "colCat=list(dict.fromkeys(colCat))#eliminate duplicated\n",
    "amenityCount=findAmenities(colCat)\n",
    "amenSize=12\n",
    "topTwelve=topNfromDict(amenityCount,amenSize)\n",
    "amenX,amenY=[],[]#생략하기..\n",
    "\n",
    "for i in range(amenSize):\n",
    "    amenX.append(topTwelve[i][0])\n",
    "    amenY.append(topTwelve[i][1])\n",
    "    #[['Wifi','Internet'],['Heating'],['essentials','shampoo','dryer'],['kitchen'],['elevator']]\n",
    "amenDic={'Wifi':0,'Heating':0,'Showering':0,'Kitchen':0,'Elevator':0}\n",
    "amenDic['Wifi']=amenY[0]+amenY[9]#Wifi+Internet\n",
    "amenDic['Heating']=amenY[1]\n",
    "amenDic['Showering']=amenY[2]+amenY[7]+amenY[8]#Essentials+Shampoo+Dryer\n",
    "amenDic['Kitchen']=amenY[3]\n",
    "amenDic['Elevator']=amenY[10]\n",
    "OHamenity=oneHotAmenities()\n",
    "OH=['Wifi','Heating','Shower','Kitchen','Elevator']\n",
    "revOHamenity=np.array(OHamenity).T\n",
    "for i in range(len(revOHamenity)):\n",
    "    preprocessed_data[OH[i]]=pd.Series(revOHamenity[i])\n",
    "preprocessed_data=pd.concat([preprocessed_data, minimumNightNewFeature], axis = 1)\n",
    "preprocessed_data=preprocessed_data.drop([\"guests_included\",\"number_of_reviews_ltm\",\"last_review\",\"reviews_per_month\",\"minimum_nights\",\"maximum_nights\",\"latitude\",\"longitude\",\"host_response_time\",\"host_response_rate\",\"amenities\"],axis=1)\n",
    "preprocessed_data=weekPricePredict(preprocessed_data)\n",
    "preprocessed_data=monthPricePredict(preprocessed_data)\n",
    "preprocessed_data = reviewRatingPreProcess(preprocessed_data)\n",
    "print(preprocessed_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* cityPreprocess : preprocess city column ( drop if it is not \"Asterdam\" and missing)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def cityPreprocess(data):\n",
    "    #drop if city is missing value\n",
    "    data_dropna=dropna(data,\"city\")\n",
    "    #drop if city is not \"Asterdam\"\n",
    "    data_city=data_dropna[data_dropna[\"city\"]==\"Amsterdam\"]\n",
    "    #reassign inde\n",
    "    data_city=data_city.reset_index(drop=True)\n",
    "    #return preprocessed data\n",
    "    return data_city\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* idPreprocess : preprocess id, host id column ( drop if it missing and wrong type)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def idPreprocess(data):\n",
    "    # drop value if id or host_id is missing value\n",
    "    data=dropna(data,\"id\")\n",
    "    data=dropna(data,\"host_id\")\n",
    "    # drop value if it has wrong type by calling dropDigit\n",
    "    data=dropDigit(data,\"id\",False)\n",
    "    data=dropDigit(data,\"host_id\",False)\n",
    "    #return preprocessed data\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "* zipcodePreprocess : preprocess zipcode column(change format, if it is out of range then change missing value)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def zipcodePreprocess(origin):\n",
    "    #find index zipcode\n",
    "    index_zipcode=findIndex(\"zipcode\",origin)\n",
    "\n",
    "\n",
    "    #change format to have only number so if value include string then remove string\n",
    "\n",
    "    for i in range(len(origin)):\n",
    "        list_temp=[]# store part of string\n",
    "        zipcode=str(origin.iloc[i,index_zipcode])\n",
    "        if zipcode==\"nan\":\n",
    "            continue;\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            for j in range(len(zipcode)):\n",
    "                if ord(zipcode[j])>=48 and ord(zipcode[j])<=57:\n",
    "                    list_temp.append(j)# if value include string then sotre list_temp\n",
    "                    \n",
    "                if j==len(zipcode)-1 and len(list_temp)>0:\n",
    "                    zipcode=zipcode[:len(list_temp)]#then only use part of number.\n",
    "                \n",
    "                    \n",
    "        origin.iat[i,index_zipcode]=zipcode #Chnage original value \n",
    "\n",
    "    #if it doesn' match format, out of range then change missing value.   \n",
    "    for i in range(len(origin)):\n",
    "        zipcode=str(origin.iloc[i,index_zipcode])\n",
    "        if zipcode==\"nan\":\n",
    "            continue;\n",
    "            \n",
    "        else:\n",
    "            if is_digit(zipcode)==False:#check right format( only number)\n",
    "                zipcode=\"nan\"\n",
    "            else:\n",
    "                if int(zipcode)<1011 or int(zipcode)>1109:#check range\n",
    "                    zipcode=\"nan\"                \n",
    "        origin.iat[i,index_zipcode]=zipcode#Chnage original value       \n",
    "    origin=origin.reset_index(drop=True)#reassign index\n",
    "    return origin#return preprocessed data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* locationPreprocess : preprocess longitude,latitude column(if it is out of range or wrong type then change missing value)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "        \n",
    "def locationPreprocess(data):\n",
    "    #find index of latitude , longitude\n",
    "    index_latitude=findIndex(\"latitude\",data)\n",
    "    index_longitude=findIndex(\"longitude\",data)\n",
    "\n",
    "    #latitude\n",
    "    for i in range(len(data)):\n",
    "        latitude=(data.iloc[i,index_latitude])\n",
    "\n",
    "        #if it isn't right type(not number)\n",
    "        if is_digit(latitude)==False:\n",
    "            latitude=np.NAN\n",
    "            latitude=float(latitude)\n",
    "            # then change original number to np.nan\n",
    "            data.iat[i,index_latitude]=latitude\n",
    "            \n",
    "        else:\n",
    "            latitude=float(latitude)\n",
    "            #if it is out of range \n",
    "            if latitude<52.28 or latitude>54:\n",
    "                latitude=np.NAN\n",
    "                latitude=float(latitude)\n",
    "                # then change original number to np.nan\n",
    "                data.iat[i,index_latitude]=latitude\n",
    "\n",
    "    #longitude\n",
    "    for i in range(len(data)):\n",
    "        longitude=(data.iloc[i,index_longitude])\n",
    "        #if it isn't right type(not number)\n",
    "        if is_digit(longitude)==False:\n",
    "            longitude=np.NAN\n",
    "            longitude=float(longitude)\n",
    "            # then change original number to np.nan\n",
    "            data.iat[i,index_longitude]=longitude\n",
    "       \n",
    "        else:\n",
    "            longitude=float(longitude)\n",
    "            #if it is out of range \n",
    "            if longitude<4.7 or longitude>5.0:\n",
    "                # then change original number to np.nan\n",
    "                longitude=np.NAN\n",
    "                data.iat[i,index_longitude]=longitude\n",
    "        \n",
    "         \n",
    "    #reassign index\n",
    "    data=data.reset_index(drop=True)\n",
    "    #return preprocessed data\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "* zipcodeLocationPreprocess : preprocess zipcode, latitude, longitude column(if all of them is missing value then drop it)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def zipcodeLocationPreprocess(data):\n",
    "    #find index zipcode,latitude, longitude\n",
    "    index_zipcode=findIndex(\"zipcode\",data)\n",
    "    index_latitude=findIndex(\"latitude\",data)\n",
    "    index_longitude=findIndex(\"longitude\",data)\n",
    "    list_drop=[]#store index of drop\n",
    "    \n",
    "    for i in range((len(data))):\n",
    "        zipcode=data.iloc[i,index_zipcode]\n",
    "        zipcode=str(data.iloc[i,index_zipcode])\n",
    "        latitude=data.iloc[i,index_latitude]\n",
    "        longitude=data.iloc[i,index_longitude]\n",
    "        latitude=float(latitude)\n",
    "        longitude=float(longitude)\n",
    "        #if all is missing value\n",
    "        if zipcode==\"nan\":\n",
    "            if np.isnan(latitude):\n",
    "                if np.isnan(longitude):\n",
    "                    #add index to list_drop\n",
    "                    list_drop.append(i)\n",
    "    #store drop data to data\n",
    "    data=data.drop(list_drop)\n",
    "    #reassign index\n",
    "    data=data.reset_index(drop=True)\n",
    "    #return preprocessed data\n",
    "    return data\n",
    "\"\"\"\n",
    "* fillLocation : preprocess zipcode, latitude, longitude column(fill missing value)\n",
    "* input: orinal data\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def fillLocation(data):\n",
    "\n",
    "    #find index zipcode, latitude, longitude\n",
    "    index_zipcode=findIndex(\"zipcode\",data)\n",
    "    index_latitude=findIndex(\"latitude\",data)\n",
    "    index_longitude=findIndex(\"longitude\",data)\n",
    "\n",
    "    #fill missing value by calling findNearst, fill function\n",
    "    for i in range(len(data)):\n",
    "        #read data\n",
    "        zipcode=data.iloc[i,index_zipcode]\n",
    "        zipcode=str(data.iloc[i,index_zipcode])\n",
    "        latitude=data.iloc[i,index_latitude]\n",
    "        longitude=data.iloc[i,index_longitude]\n",
    "        latitude=float(latitude)\n",
    "        longitude=float(longitude)\n",
    "        #list temp is store already used index\n",
    "        list_temp=[i]\n",
    "        #if zipcode is nan then fill zipcdoe\n",
    "        if zipcode==\"nan\":\n",
    "            # if latitude is nan, then using longitude to fill data\n",
    "            if np.isnan(latitude):\n",
    "                #find near_index by calling findNearest\n",
    "                near_index=findNearst(data,i,\"longitude\",list_temp)\n",
    "                #fill missing value by calling fill\n",
    "                data=fill(data,i,\"longitude\",\"zipcode\",near_index)\n",
    "            # if longitude is nan, then using latitude to fill data\n",
    "            else:\n",
    "                #find near_index by calling findNearest\n",
    "                near_index=findNearst(data,i,\"latitude\",list_temp)\n",
    "                #fill missing value by calling fill\n",
    "                data=fill(data,i,\"latitude\",\"zipcode\",near_index)\n",
    "                \n",
    "    for i in range(len(data)):\n",
    "        latitude=data.iloc[i,index_latitude]\n",
    "        longitude=data.iloc[i,index_longitude]\n",
    "        latitude=float(latitude)\n",
    "        longitude=float(longitude)\n",
    "        #list temp is store already used index\n",
    "        list_temp=[i]\n",
    "        \n",
    "        # if longitude is nan, then using zipcode fill data\n",
    "        if np.isnan(latitude):\n",
    "                #find near_index by calling findNearest\n",
    "                near_index=findNearst(data,i,\"zipcode\",list_temp)\n",
    "                #fill missing value by calling fill\n",
    "                data=fill(data,i,\"zipcode\",\"latitude\",near_index)\n",
    "        # if longitude is nan, then using zipcode fill data   \n",
    "        if np.isnan(longitude):\n",
    "                #find near_index by calling findNearest\n",
    "                near_index=findNearst(data,i,\"zipcode\",list_temp)\n",
    "                #fill missing value by calling fill\n",
    "                data=fill(data,i,\"zipcode\",\"latitude\",near_index)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* findNearst : findNearst elements\n",
    "* input: data: original data, index: using index, target: target index, list_temp: already used index\n",
    "* output: index_near: index of nearest elements\n",
    "\"\"\"\n",
    "def findNearst(data,index,target,list_temp):\n",
    "    #find index of target\n",
    "    target_index=findIndex(target,data)\n",
    "    #read data\n",
    "    nearset_target=float(data.iloc[index,target_index])\n",
    "    diff=1000\n",
    "    index_near=0\n",
    "    #find nearest data(difference is smallest) except null, already used index\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if np.isnan(float(data.iloc[i,target_index])):\n",
    "            continue;\n",
    "        elif i in list_temp:\n",
    "            continue;\n",
    "            \n",
    "        else:\n",
    "            #print(np.abs(float(data.iloc[i,target_index])-nearset_target))\n",
    "            if np.abs(float(data.iloc[i,target_index])-nearset_target)<diff:\n",
    "                index_near=i\n",
    "                diff=np.abs(float(data.iloc[i,target_index])-nearset_target)\n",
    "\n",
    "    #return index of nearest\n",
    "    return index_near\n",
    "\n",
    "\"\"\"\n",
    "* fill : fill missing value\n",
    "* input: data: original data, index: using index to fill, target: target,\n",
    "*        feature: column which is filled, index_nearest: already used index \n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def fill(data, index, target,feature,index_near):\n",
    "    feature_index=findIndex(feature,data)\n",
    "    \n",
    "    if np.isnan(float(data.iloc[index_near,feature_index])):\n",
    "        list_temp=[index_near] #store to already used index\n",
    "        #  if nearest index value is not missing value\n",
    "        while(True):\n",
    "            #find again nearest index\n",
    "            index_near=findNearst(data,index,target,list_temp)\n",
    "            #if it is null then store list_temp \n",
    "            if np.isnan(float(data.iloc[index_near,feature_index])):\n",
    "                list_temp.append(index_near)\n",
    "            else:\n",
    "                break;\n",
    "    #change original data        \n",
    "    data.iat[index,feature_index]=data.iloc[index_near,feature_index]\n",
    "    #print(index,\" \",data.iloc[index,feature_index])\n",
    "    #return preprocessed data\n",
    "    return data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "* dropna : drop row if it is null value\n",
    "* input: origin: original data, feature:used feature\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def dropna(origin,feacture):\n",
    "    #drop null value\n",
    "    origin=origin.dropna(how=\"all\",subset=[feacture])\n",
    "    #reassign index\n",
    "    origin=origin.reset_index(drop=True)\n",
    "    #return preprocessed data\n",
    "    return origin\n",
    "\"\"\"\n",
    "* dropna : drop row if it is digit or not digit\n",
    "* input: origin: original data, target: used feature\n",
    "*        what: true: drop digit, false; drop if it is not digit\n",
    "* output: preprocessed_data: data after preprocessing.\n",
    "\"\"\"\n",
    "def dropDigit(data,target,what):\n",
    "    #find index of target\n",
    "    index=findIndex(target,data)\n",
    "    #store index to delete\n",
    "    list_digit=[]\n",
    "    #what is true then drop if it digit\n",
    "    if what==True:\n",
    "        for i in range(len(data)):\n",
    "            #check it is digit by calling is_digit\n",
    "            if is_digit(data.iloc[i,index])==True:\n",
    "                list_digit.append(i)#add index to list_digit\n",
    "    #what is else then drop if it not digit\n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            #check it is digit by calling is_digit\n",
    "            if is_digit(data.iloc[i,index])==False:\n",
    "                list_digit.append(i)#add index to list_digit\n",
    "    #drop list_digit            \n",
    "    data=data.drop(list_digit)\n",
    "    #reassign data\n",
    "    data=data.reset_index(drop=True)\n",
    "    #return preprocessed data\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "* findindex : find index of target column\n",
    "* input: target: feature wanted to find index ,data: original data\n",
    "* output: index: -1 meaning fail\n",
    "\"\"\"\n",
    "def findIndex(target,data):\n",
    "    column_list=data.columns# column list store all of columns\n",
    "\n",
    "    for i in range(len(column_list)):\n",
    "        #if target exist in column_list then return this index\n",
    "        if column_list[i]==target:\n",
    "            return i\n",
    "    # else then return -1\n",
    "    return -1\n",
    "\n",
    "\"\"\"\n",
    "* is_digit : check it is digit\n",
    "* input: temp: value wanted to check\n",
    "* output: True- it is digit , False- it is not digit\n",
    "\"\"\"\n",
    "def is_digit(temp):\n",
    "    temp=str(temp)\n",
    "    #try to convert float to temp\n",
    "    try:\n",
    "        #if success then return True\n",
    "        float(temp)\n",
    "        return True\n",
    "    #if fail, then return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\"\"\"\n",
    "* OneHotPreprocess : preprocess categorical value\n",
    "* input: orinal data,target: feature wanted to onehot Encoder\n",
    "* output: onehot.columns: sequence of oridinal list: result \n",
    "\"\"\"\n",
    "def OneHotPreprocessing(data,target):\n",
    "\n",
    "    #drop null and digit\n",
    "    drop_na=dropna(data,target)\n",
    "    drop_na=dropDigit(drop_na, target,True)\n",
    "\n",
    "    #one hot encode to calling by get_dumnies\n",
    "    if target==\"property_type\":\n",
    "        one_hot=pd.get_dummies(drop_na.property_type)\n",
    "    elif target==\"room_type\":\n",
    "        one_hot=pd.get_dummies(drop_na.room_type)\n",
    "    elif target==\"bed_type\":\n",
    "        one_hot=pd.get_dummies(drop_na.bed_type)     \n",
    "\n",
    "    #sequence of oridinal list by calling index\n",
    "    lis=index(one_hot,one_hot.columns)\n",
    "    #return one_hot.columns, list\n",
    "    return one_hot.columns,lis \n",
    "\n",
    "\"\"\"\n",
    "* index: sequence of column\n",
    "* input: orinal data, column\n",
    "* output: index: sequence of column.\n",
    "\"\"\"\n",
    "def index(data,column):\n",
    "    index=[]#store index\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(column)):\n",
    "            #i data is 1\n",
    "            if data.iloc[i,j]==1:\n",
    "                index.append(j)#add index to index\n",
    "    return index\n",
    "\n",
    "\"\"\"\n",
    "* converFloat : convert float to integer\n",
    "* input: orinal data, target; wanted to conver\n",
    "* output: data: data after converting.\n",
    "\"\"\"\n",
    "def convertFloat(data, target):\n",
    "    #find index target\n",
    "    index=findIndex(target,data)\n",
    "    for i in range(len(data)):\n",
    "        #if value is not integer type\n",
    "        if float(data.iloc[i,index]).is_integer()==False:\n",
    "            #convert to integer using round\n",
    "            data.iat[i,index]=round(float(data.iloc[i,index]))\n",
    "    #return data after converting\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "* roomPreprocess : preprocess bathrooms, bedrooms, beds, acoomodates column(change format, drop if it is missing value, add column)\n",
    "* input: orinal data\n",
    "* output: bathrooms_accom:new column bathroom/accommodates , beds_accom: new column beds/accommodates\n",
    "\"\"\"\n",
    "def roomPreprocess(data):\n",
    "    index_bath=findIndex(\"bathrooms\",data)\n",
    "    index_bed=findIndex(\"beds\",data)\n",
    "    index_acom=findIndex(\"accommodates\",data)\n",
    "    list_type=[\"bathrooms\",\"bedrooms\",\"beds\",\"accommodates\"]\n",
    "\n",
    "    #drop missing value , wrong value(type error)\n",
    "    for i in range(len(list_type)):\n",
    "        data=dropDigit(data,list_type[i],False)\n",
    "        data=dropna(data,list_type[i])\n",
    "    \n",
    "    # convert wrong value(float) by calling covertFloat\n",
    "    for i in range(len(list_type)):\n",
    "        data=convertFloat(data,list_type[i])\n",
    "    bathrooms_accom=[]#store new column\n",
    "    #calculate bathroom divide accommodates\n",
    "    for i in range(len(data)):\n",
    "        bathrooms_accom.append(float(int(data.iloc[i,index_bath])/int(data.iloc[i,index_acom])))\n",
    "    beds_accom=[]\n",
    "    \n",
    "    #calculate beds divide accommodates\n",
    "    for i in range(len(data)):\n",
    "        beds_accom.append(float(int(data.iloc[i,index_bed])/int(data.iloc[i,index_acom])))\n",
    "    return bathrooms_accom, beds_accom\n",
    "def minimumNightPreprocess(data):\n",
    "    night = data[\"minimum_nights\"]\n",
    "\n",
    "    temp=(data.iloc[:,22].to_numpy())\n",
    "    temp=temp.astype(np.float32)\n",
    "\n",
    "    for i in range(len(night)): # outlier detection\n",
    "        if((float(night[i]) > np.mean(temp) + 3 * np.std(temp)) or (float(night[i]) < np.mean(temp) -  3 * np.std(temp))):\n",
    "            night[i] = np.mean(temp)\n",
    "    # print(night)\n",
    "    night = pd.DataFrame({'minimum_nights': night, 'minimum_nights_check': 0})\n",
    "    night[\"minimum_nights_check\"] = 0\n",
    "\n",
    "    for i in range(len(night)): # minimum night가 작으면 0 크면 1로 feature creation\n",
    "        if(float(night.iloc[i,0]) >= 5):\n",
    "            night.iloc[i,1] = 1\n",
    "        else:\n",
    "            night.iloc[i,1] = 0\n",
    "\n",
    "    return night[\"minimum_nights_check\"]\n",
    "\n",
    "\n",
    "def weekPricePredict(datat):\n",
    "    price_week = datat[[\"price\", \"weekly_price\"]]\n",
    "    price_origin = datat[\"price\"]\n",
    "    week_origin = datat[\"weekly_price\"]\n",
    "    \n",
    "    price_week_noNan = price_week.dropna() # drop nan from week\n",
    "    price1 = price_week_noNan[\"price\"]\n",
    "    week = price_week_noNan[\"weekly_price\"]\n",
    "\n",
    "    reg = linear_model.LinearRegression() # price and week linear regression\n",
    "    reg.fit(price1[:, np.newaxis], week)\n",
    "\n",
    "    pw = reg.predict(price_origin[:,np.newaxis]) #predicted week_price\n",
    "    \n",
    "    for i in range(len(price_origin)):  # enter predicted data at week nan data\n",
    "        w = float(week_origin[i])\n",
    "        if(np.isnan(w)):\n",
    "            datat[\"weekly_price\"][i] = int(pw[i])\n",
    "\n",
    "    return datat\n",
    "\n",
    "# month 가격 채워넣기\n",
    "def monthPricePredict(datat):\n",
    "    price_month = datat[[\"price\", \"monthly_price\"]]\n",
    "    price_origin = datat[\"price\"]\n",
    "    month_origin = datat[\"monthly_price\"]\n",
    "\n",
    "    price_month_noNan = price_month.dropna() # drop nan from month\n",
    "    price2 = price_month_noNan[\"price\"]\n",
    "    month = price_month_noNan[\"monthly_price\"]\n",
    "\n",
    "    reg2 = linear_model.LinearRegression() # price and month linear regression\n",
    "    reg2.fit(price2[:, np.newaxis], month)\n",
    "\n",
    "    pm = reg2.predict(price_origin[:,np.newaxis]) #predicted month_price\n",
    "\n",
    "    for i in range(len(price_origin)):  # enter month nan data to predicted data\n",
    "        m = float(month_origin[i])\n",
    "        if(np.isnan(m)):\n",
    "            datat[\"monthly_price\"][i] = int(pm[i])\n",
    "\n",
    "    return datat\n",
    "#####'amenities'분리해주는 functions######\n",
    "#####'amenities'분리해주는 functions######\n",
    "def trimming(strList):\n",
    "    for i in range(len(strList)):\n",
    "        #trim(strList[i])\n",
    "        strList[i]=splitString(strList[i])\n",
    "#str양끝에 특수기호가 있으면 벗겨줌\n",
    "def trim(str):\n",
    "    while(not(str.isalnum()) and not(splitString(str).isalnum())):\n",
    "        str=str.strip()\n",
    "        str=str.strip(']')\n",
    "        str=str.strip('[')\n",
    "        str=str.strip(':')\n",
    "        str=str.strip('{')\n",
    "        str=str.strip('}')\n",
    "        str=str.strip('\\'')\n",
    "        str=str.strip('\"')\n",
    "        str=str.strip('_')\n",
    "        str=str.strip('-')\n",
    "        str=str.strip('\\\"')\n",
    "        str=str.strip('}')\n",
    "#str을에서 특수기호 기준으로 분리해줌 \n",
    "def splitString(str):\n",
    "    tmp=str\n",
    "    tmp=\"\".join(tmp.split())\n",
    "    tmp=\"\".join(tmp.split('/'))\n",
    "    tmp=\"\".join(tmp.split('-'))\n",
    "    tmp=\"\".join(tmp.split(':'))\n",
    "    tmp=\"\".join(tmp.split('.'))\n",
    "    tmp=\"\".join(tmp.split('_'))\n",
    "    tmp=\"\".join(tmp.split('#'))\n",
    "    tmp=\"\".join(tmp.split('\"'))\n",
    "    tmp=\"\".join(tmp.split('\\''))\n",
    "    tmp=\"\".join(tmp.split('{'))\n",
    "    tmp=\"\".join(tmp.split('}'))\n",
    "    tmp=\"\".join(tmp.split('['))\n",
    "    tmp=\"\".join(tmp.split(']'))\n",
    "    tmp=\"\".join(tmp.split('('))\n",
    "    tmp=\"\".join(tmp.split(')'))\n",
    "    tmp=\"\".join(tmp.split('<'))\n",
    "    tmp=\"\".join(tmp.split('>'))\n",
    "    return tmp\n",
    "#유니크한 amenity들의 개수 세기 \n",
    "def findAmenities(colCat):\n",
    "    amenitycount={colCat[0]:0}\n",
    "    for i in range(len(colCat)):\n",
    "        amenitycount[colCat[i]]=0\n",
    "    for i in range(len(preprocessed_data)):\n",
    "        for x in amenitycount:\n",
    "            if str(preprocessed_data['amenities'][i]).find(x)>0:\n",
    "                amenitycount[x]=amenitycount[x]+1\n",
    "    return amenitycount;#return: {'amenity이름':amenity의 전체빈도수}\n",
    "\n",
    "#dic(dictionary) 중에서 빈도수가 가장높은 n개만 뽑아서 큰순서로 리턴\n",
    "def topNfromDict(dic,n):\n",
    "    topN=[]\n",
    "    sortedDict=sorted(dic.items(),key=operator.itemgetter(1),reverse=True)#sort by value in reverse\n",
    "    for i in range(n):\n",
    "        item=sortedDict[i]\n",
    "        topN.append(item)\n",
    "    return topN #return[('key',value)*n]array\n",
    "def oneHotAmenities():\n",
    "    OneHotAmenities=[]\n",
    "    for i in range(len(preprocessed_data)):\n",
    "        count=[0,0,0,0,0]\n",
    "        if re.search('Wifi'or'Internet',preprocessed_data['amenities'].iloc[i],re.IGNORECASE):\n",
    "            count[0]=count[0]+1\n",
    "        if re.search('Heating',preprocessed_data['amenities'].iloc[i],re.IGNORECASE):\n",
    "            count[1]=count[1]+1\n",
    "        if re.search('essentials'or'shampoo'or'dryer',preprocessed_data['amenities'].iloc[i],re.IGNORECASE):\n",
    "            count[2]=count[2]+1\n",
    "        if re.search('kitchen',preprocessed_data['amenities'].iloc[i],re.IGNORECASE):\n",
    "            count[3]=count[3]+1\n",
    "        if re.search('elevator',preprocessed_data['amenities'].iloc[i],re.IGNORECASE):\n",
    "            count[4]=count[4]+1\n",
    "        OneHotAmenities.append(count)\n",
    "    return OneHotAmenities\n",
    "def reviewRatingPreProcess(data):\n",
    "    review_rating = data[\"review_scores_rating\"]\n",
    "\n",
    "    for i in range(len(review_rating)):\n",
    "        r = float(review_rating[i])\n",
    "        if(np.isnan(r)): # 빈 값이면 0으로 채우기\n",
    "            data[\"review_scores_rating\"][i] = 0\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a314fc90e995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcityPreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data=cityPreprocess(data) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
